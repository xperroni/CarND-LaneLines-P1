{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lane Regresor - Finding Lane Lines on the Road** \n",
    "***\n",
    "This project uses the tools presented in the first lesson to identify lane lines on the road. First a pipeline of visual filters is used to identify edges on input images, then a set of line segments is extracted by applying the Hough Transform, and finally the position of the lane lines is derived from the detected line segments.\n",
    "\n",
    "---\n",
    "\n",
    "We start by importing general use packages and defining some basic visual filter functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def grayscale(image):\n",
    "    r'''Converts the given BGR image to grayscale.\n",
    "    '''\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def canny(grays, low_threshold, high_threshold):\n",
    "    r'''Applies the Canny transform (controlled by the given arguments)\n",
    "        to the given grayscale image, returning an edge map as result.\n",
    "    '''\n",
    "    return cv2.Canny(grays, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def gaussian_blur(image, kernel_size):\n",
    "    r'''Applies a Gaussian smoothing transform of given kernel size to the image. \n",
    "    '''\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(image, *vertices):\n",
    "    r'''Return a transformed copy of the input image, where everything outside\n",
    "        the polygon delimited by the given vertice list is blacked out.\n",
    "    '''\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(image)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, np.array([vertices]), ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def weighted_img(image, markers, α=0.8, β=1., λ=0.):\n",
    "    r'''Merge the given input and marker images.\n",
    "    '''\n",
    "    return cv2.addWeighted(markers, α, image, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define classes for extracting and managing lines and line segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from sys import maxsize\n",
    "\n",
    "\n",
    "class Line(list):\n",
    "    r'''A line in 2D space, defined in terms of a slope `m` and an offset `b` such that `y = m * x + b`.\n",
    "    '''\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        r'''Create a new line that passes through given points `(x1, y1)` and `(x2, y2)`.\n",
    "        '''\n",
    "        list.__init__(self)\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        m = (dy / dx) if dx != 0 else maxsize\n",
    "        b = y2 - x2 * m\n",
    "        self.extend([m, b])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        r'''Compute `y` such that `y = m * x + b` rounded down to integer precision.\n",
    "        '''\n",
    "        (m, b) = self\n",
    "        return int(x * m + b)\n",
    "\n",
    "    def draw(self, img, x1, x2, color=[255, 0, 0], thickness=2):\n",
    "        r'''Draw this line on the given image, according to given arguments.\n",
    "        '''\n",
    "        y1 = self(x1)\n",
    "        y2 = self(x2)\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "    def update(self, line, λ=0.98):\n",
    "        r'''Update this line's parameters according to the given arguments.\n",
    "        '''\n",
    "        (m, b) = self\n",
    "        (m_i, b_i) = line\n",
    "        self[0] = λ * m + (1 - λ) * m_i\n",
    "        self[1] = λ * b + (1 - λ) * b_i\n",
    "    \n",
    "    @property\n",
    "    def m(self):\n",
    "        return self[0]\n",
    "    \n",
    "    @property\n",
    "    def b(self):\n",
    "        return self[1]\n",
    "\n",
    "        \n",
    "_Segment = namedtuple('_Segment', ['x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "class Segment(_Segment):\n",
    "    r'''A line segment delimited by two points `(x1, y1)` and `(x2, y2)`.\n",
    "    '''\n",
    "    def __new__(cls, x1, y1, x2, y2):\n",
    "        r'''Create a new line segment.\n",
    "        '''\n",
    "        return _Segment.__new__(cls, x1, y1, x2, y2)\n",
    "\n",
    "    @property\n",
    "    def slope(self):\n",
    "        (x1, y1, x2, y2) = self\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        return (dy / dx) if dx != 0 else maxsize\n",
    "        \n",
    "\n",
    "class Segments(list):\n",
    "    r'''A list of line segments.\n",
    "    '''\n",
    "    def __init__(self, *items):\n",
    "        r'''Create a new list of line segments.\n",
    "        '''\n",
    "        list.__init__(self)\n",
    "        for item in items:\n",
    "            self.append(item)\n",
    "\n",
    "    def dataset(self):\n",
    "        r'''Convert this list of segments into a pair of matrices `(X, y)` suitable for input into\n",
    "            regression methods.\n",
    "            \n",
    "            Each line segment `(x1, y1, x2, y2)` is converted to a sequence of `x2 - x1 + 1` points\n",
    "            along the line that crosses `(x1, y1)` and `(x2, y2)`.\n",
    "        '''\n",
    "        (X, y) = ([], [])\n",
    "        for segment in self:\n",
    "            (x1, y1, x2, y2) = segment\n",
    "            line = Line(x1, y1, x2, y2)\n",
    "            for x in range(x1, x2 + 1):\n",
    "                X.append(x)\n",
    "                y.append(line(x))\n",
    "\n",
    "        return (np.array([X]).T, np.array(y))\n",
    "\n",
    "    def select(self, criterion):\n",
    "        r'''Returns a new segment list containing only the elements that match the given criterion.\n",
    "        '''\n",
    "        selected = [segment for segment in self if criterion(segment)]\n",
    "        return Segments(*selected)\n",
    "\n",
    "\n",
    "class HoughSegments(Segments):\n",
    "    r'''List of segments filled from the output of a Hough Transform.\n",
    "    '''\n",
    "    def __init__(self, img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "        r'''Create a list of segments following edges on the input image.\n",
    "\n",
    "            Input should be a line image, such as the output of a Canny transform.\n",
    "\n",
    "            Lines are found by computing the Hough transform of the input image, then pairing down\n",
    "            results according to the given arguments.\n",
    "        '''\n",
    "        Segments.__init__(self)\n",
    "        for segments in cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), min_line_len, max_line_gap):\n",
    "            for segment in segments:\n",
    "                self.append(Segment(*segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implement the Lane Regressor, a simple processing pipeline for identifying lane lines in video streams. It works by performing the following steps for each frame in a record:\n",
    "\n",
    "1. Convert the frame to grayscale;\n",
    "2. Apply Gaussian smoothing;\n",
    "3. Apply the Canny transform to extract edges;\n",
    "4. Cut out a triangular region with vertices on the image center and lower corners;\n",
    "5. Use the Hough Transform to identify a set of line segments in the cut-out region;\n",
    "6. Separate the identified segments in two sets with negative and positive slope;\n",
    "7. Use RANSAC to derive an optimal representative segment for each set;\n",
    "8. Use the RANSAC-derived representatives to update (or initialize) running estimates for the position of lane lines.\n",
    "\n",
    "Steps 1-4 prepare the image frame for input to the Hough Transform line segment finder, with the objective of removing information not related to lane lines. It is expected that the output of step 5 will be a collection of line segments mostly clustered around the two lane lines. These are then separated in two sets based on slope signal: segments of negative slope are expected to be clustering on the left lane line, and positive slopes, on the right. This is a consequence of lane lines always looking somewhat slanted, owing to the way parallel lines drawn on the ground appear to converge as they reach for the horizon.\n",
    "\n",
    "The two line segment sets are transformed into sets of points, which are used to train separate RANSAC regressors. RANSAC was chosen due to its ability to work well with data containing a clear trend but polluted with a relatively small number of outliers, as is the case here. The fitted lines are then used to update (or initialize) two running estimates of the position parameters of lane lines, which are drawn to the output frame. These estimates implement a model of gradual change over time, reflecting the way lane lines move slowly across the visual field in input videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def filter_pipeline(image):\n",
    "    r'''Pipeline of visual filters used to preprocess input images prior to line detection.\n",
    "    '''\n",
    "    (y_n, x_n) = image.shape[:2]\n",
    "    x_c = x_n // 2\n",
    "    x_l = x_n - 1\n",
    "    y_c = y_n // 2\n",
    "    y_l = y_n - 1\n",
    "\n",
    "    grays = grayscale(image)\n",
    "    grays = gaussian_blur(grays, 5)\n",
    "    grays = canny(grays, 50, 150)\n",
    "    grays = region_of_interest(grays, (0, y_l), (x_c, y_c), (x_l, y_l))\n",
    "    \n",
    "    return grays\n",
    "\n",
    "\n",
    "class LaneRegressor(object):\n",
    "    r'''Lane line position online regressor.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        r'''Create a new regressor.\n",
    "        '''\n",
    "        self.lines = dict()\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        r'''Process the given image frame.\n",
    "        '''\n",
    "        segments = HoughSegments(filter_pipeline(image), 1, np.pi / 180.0, 10, 10, 2)\n",
    "        \n",
    "        (y_n, x_n) = image.shape[:2]\n",
    "        x_c = x_n // 2\n",
    "        x_l = x_n - 1\n",
    "        m = y_n / x_n\n",
    "        \n",
    "        self.update('l', segments, lambda s: s.slope < -m)\n",
    "        self.update('r', segments, lambda s: m < s.slope < maxsize)\n",
    "        \n",
    "        lines_img = np.zeros(image.shape, dtype=image.dtype)\n",
    "        self.draw('l', lines_img, 0, x_c)\n",
    "        self.draw('r', lines_img, x_c, x_l)\n",
    "\n",
    "        return weighted_img(lines_img, image)\n",
    "\n",
    "    def draw(self, key, image, x1, x2):\n",
    "        r'''Draw the named line on the image, if found. Otherwise does nothing.\n",
    "        '''\n",
    "        line = self.lines.get(key)\n",
    "        if line == None:\n",
    "            return\n",
    "        \n",
    "        line.draw(image, x1, x2, thickness=7)\n",
    "    \n",
    "    def update(self, key, segments, criterion):\n",
    "        r'''Update (or initialize) the running estimate for the named line, based on data\n",
    "            extracted from the given segment list.\n",
    "        '''\n",
    "        selected = segments.select(criterion)\n",
    "        if len(selected) == 0:\n",
    "            return\n",
    "        \n",
    "        (X, y) = selected.dataset()\n",
    "        model = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        (x1, x2) = (X.min(), X.max())\n",
    "        y1 = int(model.predict(x1)[0])\n",
    "        y2 = int(model.predict(x2)[0])\n",
    "        updating = Line(x1, y1, x2, y2)\n",
    "\n",
    "        line = self.lines.get(key)\n",
    "        if line == None:\n",
    "            self.lines[key] = updating\n",
    "        else:\n",
    "            line.update(updating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting tests, let's define a few conveniences for processing and diplaying videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# Template HTML snippet for embedding a video display into the notebook.\n",
    "VIDEO_TAG = r'''\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"%s?t=%f\">\n",
    "</video>\n",
    "'''\n",
    "\n",
    "\n",
    "def process(path_in, path_out):\n",
    "    r'''Process the video at the input path, saving the result to the output video file path.\n",
    "    '''\n",
    "    clip1 = VideoFileClip(path_in)\n",
    "    white_clip = clip1.fl_image(LaneRegressor())\n",
    "    # Display processing progress inline.\n",
    "    %time white_clip.write_videofile(path_out, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with all pieces in place, let's start by testing the regressor on the first example video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:10<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 1min 4s, sys: 2.36 s, total: 1min 7s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "process('solidWhiteRight.mp4', 'white.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be visualized inline using the snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4?t=0.298320\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(VIDEO_TAG % ('white.mp4', random())) # the second, random parameter forces the browser to reload the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:36<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 3min 36s, sys: 9.1 s, total: 3min 46s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "process('solidYellowLeft.mp4', 'yellow.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4?t=0.886862\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(VIDEO_TAG % ('yellow.mp4', random()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last for the challenge video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:22<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 2min 13s, sys: 5.5 s, total: 2min 19s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "process('challenge.mp4', 'extra.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4?t=0.848098\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(VIDEO_TAG % ('extra.mp4', random()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "The Lane Regressor is a simple processing pipeline for identifying lane lines in video streams. It combines visual processing and regression techniques to iteratively compute an estimate for two image regions within which the left and right lane lines are expected to be. Experiments show it performs adequately on the example videos.\n",
    "\n",
    "As proposed the system includes a number of parameters (such as those for the Canny and Hough Transforms) for which there's no clear optimization procedure, requiring values to be determined manually through trial-and-error; consequently there's no indication the settings used for the cases above will be optimal for differing inputs. Line identification is primitive, with slope being the only parameter to judge whether a segment should be discarded or kept for further processing; this could make the algorithm mistake some other object for a lane line, if it produces more segments of the right slope. The use of a random regressor (RANSAC) may cause similar or repeated inputs to produce noticeably different outputs, which may lead to consistency issues. The running estimate model assumes the current position of lane lines in the visual field varies smoothly over time, but in principle there's no guarantee that will always be the case.\n",
    "\n",
    "Addressing the above issues would go a long way towards improving system performance. Still, the general procedure outlined at this point &ndash; a filter pipeline to extract relevant visual information, followed by extraction of model instances (line segments in this case) that are used to generate input data to an online learning system &ndash; showed promise, deserving further investigation."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
